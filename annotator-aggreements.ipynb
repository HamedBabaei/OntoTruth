{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dd584a-d578-4451-bb2f-68b337a69bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming you have a file called data.json\n",
    "with open('dataset/60qas_ans.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf59d52-ce59-4304-916a-9973149affa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentence-Transformer Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7edf09-cb66-4455-a600-71f2359d7259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q#': 1,\n",
       " 'Question': 'What are the common toppings of a Margherita Pizza?',\n",
       " 'Category': 'IND',\n",
       " 'SPARQL': '\\nPREFIX pizza: <http://www.co-ode.org/ontologies/pizza/pizza.owl#>\\n\\nSELECT ?topping WHERE {\\n  pizza:MargheritaPizza pizza:hasTopping ?topping .\\n}\\n',\n",
       " 'FC_Ans': 'Mozzarella and tomato',\n",
       " 'GS_Ans': 'MozzarellaTopping, TomatoTopping |MargheritaPizza has hasTopping some (MozzarellaTopping and TomatoTopping).'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741a0e82-37d4-4988-83d0-feb1ee539865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WRONG answers: 8,  [14, 15, 17, 44, 47, 48, 50, 58]\n"
     ]
    }
   ],
   "source": [
    "wrongs = [item['Q#'] for item in data if item['FC_Ans'] == \"WRONG\" or item['GS_Ans'] == \"WRONG\"]\n",
    "\n",
    "print(f\"Total WRONG answers: {len(wrongs)},  {wrongs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a843a2-e6df-4864-8b37-ae3c777ae100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 11:09:07.123565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-30 11:09:07.191440: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-30 11:09:07.211053: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-30 11:09:07.330141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 11:09:13.397011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afce9ba3d0864c15aa0b124e31dbabc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c89991a2da4635b757267c49f75845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4404f83591a46189ca478c752670100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fa58dc01ee46de803cb808fba03fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce211f4b9af49b1ae7a25401e429655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a072fe31a2af4a5bb6e791f1dd6090b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b4566fba02496f8664ce3921283e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aec40a935849dbb89d4a571f56e8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9a90fe65734f5ab3ac8bd667942da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953b68623a734500b86185b44ab46e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49d931872a241b9bb743025003fd06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22dc6d5-1003-4dcf-a5b6-0d931b0ee663",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator1 = [item['FC_Ans'] for item in data if item['Q#'] not in wrongs]\n",
    "annotator2 = [item['GS_Ans'] for item in data if item['Q#'] not in wrongs]\n",
    "\n",
    "annotator1_embedding = model.encode(annotator1)\n",
    "annotator2_embedding = model.encode(annotator2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a17f46-e6a7-46fb-a56c-000b714d890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotator1), len(annotator2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d79fa6-eb18-4f9c-8bf2-926aa16622d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = model.similarity(annotator1_embedding, annotator2_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c63d72d-9ede-48e2-bdda-db232a7bf340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator agreements: 0.4878907341223497\n"
     ]
    }
   ],
   "source": [
    "agreements = []\n",
    "for idx in range(len(annotator1)):\n",
    "    agreements.append(similarities[idx][idx].item())\n",
    "    \n",
    "aggreement_score = sum(agreements)/len(annotator1)\n",
    "\n",
    "print(\"Annotator agreements:\", aggreement_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608009e-7f75-4171-b583-1fd758c5bcf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LLM as a judge agreament maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a891c811-8a97-4f87-a528-848e2b0005c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"I have two annotators who answered the same question based on an ontology. \n",
    "Compare their answers and judge whether they agree or disagree.\n",
    "If they disagree, explain the nature of the disagreement (e.g., different entities, relations, interpretations, or missing concepts).\n",
    "Next, provide a single answer based on two annotators. This response should be straightforward with no extra explanation. \n",
    "\n",
    "<question> \n",
    "{question}\n",
    "</question> \n",
    "\n",
    "\n",
    "<ontology> \n",
    "{ontology}\n",
    "</ontology> \n",
    "\n",
    "<Annotator 1 Answer>\n",
    "{annotator1}\n",
    "</Annotator 1 Answer>\n",
    "\n",
    "<Annotator 2 Answer>\n",
    "{annotator2}\n",
    "</Annotator 2 Answer>\n",
    "\n",
    "Return your output as a following format:\n",
    "\n",
    "{'agreement': 'agree', 'rationale': '...', 'answer': '...'}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf0f9f3-3ffc-411d-9883-99874d4f4af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 11:44:48.549150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-30 11:44:48.569552: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-30 11:44:48.575838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-30 11:44:48.590703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 11:44:53.023586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import scripts, config\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "ontology_text = scripts.load_ontology(\"dataset/pizza.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae7d883-36cb-4e42-bd1d-d60303467aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=config.openai_token)\n",
    "\n",
    "functions = [\n",
    "  {\n",
    "    \"name\": \"evaluate_characteristic\",\n",
    "    \"description\": \"Extracting the exact `agreement` and `rationale` from the given text.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"agreement\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"A agree or disagree string values describing whatever two annotator are agree or not.\",\n",
    "        },\n",
    "        \"rationale\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The explanation for the assigned rating.\"\n",
    "        },\n",
    "        \"answer\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Single unified answer if both are agree.\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"agreement\", \"rationale\", \"answer\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def save_json(data, path):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f524806c-3096-4f95-b5db-647fb2f5ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q#': 1,\n",
       " 'Question': 'What are the common toppings of a Margherita Pizza?',\n",
       " 'Category': 'IND',\n",
       " 'SPARQL': '\\nPREFIX pizza: <http://www.co-ode.org/ontologies/pizza/pizza.owl#>\\n\\nSELECT ?topping WHERE {\\n  pizza:MargheritaPizza pizza:hasTopping ?topping .\\n}\\n',\n",
       " 'FC_Ans': 'Mozzarella and tomato',\n",
       " 'GS_Ans': 'MozzarellaTopping, TomatoTopping |MargheritaPizza has hasTopping some (MozzarellaTopping and TomatoTopping).'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f6d05b6-1bc5-4633-a122-c2ef28660ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d93a49fdbe54a01a2554f9b1e683309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_data = []\n",
    "for item in tqdm(data):\n",
    "    question = item['Question']\n",
    "    annotator1 = item['FC_Ans']\n",
    "    annotator2 = item['GS_Ans']\n",
    "    \n",
    "    conversation =    [\n",
    "        {\"role\": \"system\", \"content\": \"You are a LLM-as-a-Judge System.\"}, \n",
    "        {\"role\": \"user\", \"content\": prompt_template.replace(\"{question}\", question).replace(\"{annotator1}\", annotator1).replace(\"{annotator2}\", annotator2).replace(\"{ontology}\", ontology_text)}\n",
    "    ] \n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=conversation,\n",
    "                functions=functions\n",
    "            )\n",
    "\n",
    "            inference = eval(completion.choices[0].message.function_call.arguments)\n",
    "            break\n",
    "        except:\n",
    "            print(\"sleep for 5 seconds\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "    new_data.append({\n",
    "        \"Q#\": item['Q#'],\n",
    "        \"Question\": item['Question'],\n",
    "        \"Category\": item['Category'],\n",
    "        \"FC_Ans\": item['FC_Ans'],\n",
    "        \"GS_Ans\": item['GS_Ans'],\n",
    "        \"agreement\": inference\n",
    "    })\n",
    "    save_json(new_data, \"AI-Judger.json\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde9df0-1a33-4ff0-afca-70fac8c37b63",
   "metadata": {},
   "source": [
    "# Agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587f03c1-1edd-46b8-a73f-c4a7c3a189ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming you have a file called data.json\n",
    "with open('datasets/AI-Judger.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610ef19b-4c08-4c8b-8825-af67683d53a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q#': 1,\n",
       " 'Question': 'What are the common toppings of a Margherita Pizza?',\n",
       " 'Category': 'IND',\n",
       " 'FC_Ans': 'Mozzarella and tomato',\n",
       " 'GS_Ans': 'MozzarellaTopping, TomatoTopping |MargheritaPizza has hasTopping some (MozzarellaTopping and TomatoTopping).',\n",
       " 'agreement': {'agreement': 'agree',\n",
       "  'rationale': \"Both annotators mention the same toppings for a Margherita Pizza: Mozzarella and Tomato. Annotator 2 uses the terminology from the ontology ('MozzarellaTopping', 'TomatoTopping') but these directly correlate with 'Mozzarella' and 'Tomato' from Annotator 1's answer.\",\n",
       "  'answer': 'Mozzarella and tomato'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bbed08-6312-45a7-afe8-0281e006fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreements: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "ag2id = {\"agree\": 1, \"disagree\":0}\n",
    "agreements = [ag2id[item['agreement']['agreement']] for item in data]\n",
    "\n",
    "print(\"agreements:\", sum(agreements)/len(agreements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45bdeec-5b6a-4cde-982b-c546f5b2b794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
